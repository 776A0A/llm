{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoJOuVYBfAT6"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install llama-index\n",
        "!pip install langchain\n",
        "!pip install faiss-gpu\n",
        "!pip install openai\n",
        "\n",
        "# import locale\n",
        "# locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "# !pip install protobuf\n",
        "# !pip install --upgrade protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BON47vSvXIb2"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzcIpnJ2Yk9u"
      },
      "outputs": [],
      "source": [
        "!pip install pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBNW8FaNbbt3"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from llama_index import (\n",
        "    GPTVectorStoreIndex,\n",
        "    ServiceContext,\n",
        "    StorageContext,\n",
        "    download_loader,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "years = [2022, 2021, 2020, 2019]\n",
        "UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)\n",
        "\n",
        "loader = UnstructuredReader()\n",
        "\n",
        "doc_set = {}\n",
        "all_docs = []\n",
        "\n",
        "for year in years:\n",
        "    year_docs = loader.load_data(\n",
        "        file=Path(f\"/content/drive/MyDrive/Colab Notebooks/data/UBER/UBER_{year}.html\"),\n",
        "        split_documents=False,\n",
        "    )\n",
        "    for d in year_docs:\n",
        "        d.extra_info = {\"year\": year}\n",
        "    doc_set[year] = year_docs\n",
        "    all_docs.extend(year_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI3Pe3y0aGxG",
        "outputId": "0b0da613-22fc-47be-fc13-a1b7345b2d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "2019  2020  2021  2022\troot\n"
          ]
        }
      ],
      "source": [
        "from llama_index import LangchainEmbedding\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR_OPENAI_API_KEY'\n",
        "\n",
        "embed_model = LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
        ")\n",
        "\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model, chunk_size_limit=512)\n",
        "index_set = {}\n",
        "\n",
        "for year in years:\n",
        "  storage_context = StorageContext.from_defaults()\n",
        "  cur_index = GPTVectorStoreIndex.from_documents(\n",
        "      doc_set[year],\n",
        "      service_context=service_context,\n",
        "      storage_context=storage_context\n",
        "  )\n",
        "  index_set[year] = cur_index\n",
        "  storage_context.persist(persist_dir=f'./storage/{year}')\n",
        "\n",
        "!pwd\n",
        "!ls storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH6BsSD5c_S1",
        "outputId": "f4b77130-a58b-4d99-9b12-5de3b40c2c48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:llama_index.llm_predictor.base:Unknown max input size for gpt-3.5-turbo, using defaults.\n"
          ]
        }
      ],
      "source": [
        "from llama_index import (\n",
        "    GPTListIndex,\n",
        "    LLMPredictor,\n",
        "    ServiceContext,\n",
        "    load_graph_from_storage,\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from llama_index.indices.composability import ComposableGraph\n",
        "\n",
        "index_summaries = [f\"UBER 10-k Filing for {year} fiscal year\" for year in years]\n",
        "\n",
        "llm_predictor = LLMPredictor(\n",
        "    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=512)\n",
        ")\n",
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
        "storage_context = StorageContext.from_defaults()\n",
        "\n",
        "graph = ComposableGraph.from_indices(\n",
        "    GPTListIndex,\n",
        "    [index_set[y] for y in years],\n",
        "    index_summaries=index_summaries,\n",
        "    service_context=service_context,\n",
        "    storage_context=storage_context,\n",
        ")\n",
        "\n",
        "root_id = graph.root_id\n",
        "\n",
        "storage_context.persist(persist_dir=f\"./storage/root\")\n",
        "\n",
        "graph = load_graph_from_storage(\n",
        "    root_id=root_id, service_context=service_context, storage_context=storage_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dvNr8YOxgqCu"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "from llama_index.langchain_helpers.agents import (\n",
        "    LlamaToolkit,\n",
        "    create_llama_chat_agent,\n",
        "    IndexToolConfig,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wIBLS4VKhS72"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.query.query_transform.base import DecomposeQueryTransform\n",
        "\n",
        "decompose_transform = DecomposeQueryTransform(llm_predictor, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iKgTVBcthjWU"
      },
      "outputs": [],
      "source": [
        "from llama_index.query_engine.transform_query_engine import TransformQueryEngine\n",
        "\n",
        "custom_query_engines = {}\n",
        "\n",
        "for index in index_set.values():\n",
        "    query_engine = index.as_query_engine()\n",
        "    query_engine = TransformQueryEngine(\n",
        "        query_engine,\n",
        "        query_transform=decompose_transform,\n",
        "        transform_extra_info={\"index_summary\": index.index_struct.summary},\n",
        "    )\n",
        "    custom_query_engines[index.index_id] = query_engine\n",
        "\n",
        "custom_query_engines[graph.root_id] = graph.root_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\", verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "uloVvF5bjKDt"
      },
      "outputs": [],
      "source": [
        "graph_config = IndexToolConfig(\n",
        "    query_engine=query_engine,\n",
        "    name=f\"Graph Index\",\n",
        "    description=\"useful for when you want to answer queries that require analyzing multiple SEC 10-K documents for Uber.\",\n",
        "    tool_kwargs={\"return_direct\": True},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qGPSbcU6jez8"
      },
      "outputs": [],
      "source": [
        "index_configs = []\n",
        "for y in years:\n",
        "    query_engine = index_set[y].as_query_engine(similarity_top_k=3)\n",
        "    tool_config = IndexToolConfig(\n",
        "        query_engine=query_engine,\n",
        "        name=f\"Vector Index {y}\",\n",
        "        description=f\"useful for when you want to answer queries about the {y} SEC 10-K for Uber\",\n",
        "        tool_kwargs={\"return_direct\": True},\n",
        "    )\n",
        "    index_configs.append(tool_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "CYQNXYRTkA6U"
      },
      "outputs": [],
      "source": [
        "toolkit = LlamaToolkit(index_configs=index_configs + [graph_config])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hqfAhY8lkIC0"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=512)\n",
        "\n",
        "agent_chain = create_llama_chat_agent(toolkit, llm, memory=memory, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "MNOkQr24lRke",
        "outputId": "35d2c96c-aa88-4524-a562-87bcb20dccf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Hello Bob! How can I assist you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello Bob! How can I assist you today?'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_chain.run(input=\"hi, i am bob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "UXwOxEjUlbtM",
        "outputId": "d467fb41-4bca-4337-b09a-93cea9065ffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Vector Index 2020\n",
            "Action Input: \"What were some of the biggest risk factors in 2020 for Uber?\"\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m\n",
            "Some of the biggest risk factors in 2020 for Uber included:\n",
            "\n",
            "1. Safety and security risks for Drivers and riders, including potential robbery, assault, violent or fatal attacks, and other criminal acts.\n",
            "\n",
            "2. Inability to collect the entire service fee for certain cash-based trips.\n",
            "\n",
            "3. Loss or material modification of credit card acceptance privileges.\n",
            "\n",
            "4. Compliance risks with respect to a variety of rules and regulations, including anti-money laundering laws.\n",
            "\n",
            "5. Inability to attract and engage Drivers, consumers, merchants, shippers, and carriers, as well as contractors and consultants that support global operations.\n",
            "\n",
            "6. Lack of protections and benefits for independent workers.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nSome of the biggest risk factors in 2020 for Uber included:\\n\\n1. Safety and security risks for Drivers and riders, including potential robbery, assault, violent or fatal attacks, and other criminal acts.\\n\\n2. Inability to collect the entire service fee for certain cash-based trips.\\n\\n3. Loss or material modification of credit card acceptance privileges.\\n\\n4. Compliance risks with respect to a variety of rules and regulations, including anti-money laundering laws.\\n\\n5. Inability to attract and engage Drivers, consumers, merchants, shippers, and carriers, as well as contractors and consultants that support global operations.\\n\\n6. Lack of protections and benefits for independent workers.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_chain.run(input=\"What were some of the biggest risk factors in 2020 for Uber?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "uUA7Ke1rl130",
        "outputId": "786393a4-385c-464d-bd4c-c03fbf985d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Vector Index 2022\n",
            "Action Input: Compare/contrast the risk factors described in the Uber 10-K across years.\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "In the Uber 10-K for 2022, the risk factors discussed include the potential for Drivers to be classified as employees, workers, or quasi-employees instead of independent contractors, the competitive nature of the mobility, delivery, and logistics industries, the potential for operating expenses to increase significantly, the need to attract and maintain a critical mass of Drivers, consumers, merchants, Shippers, and Carriers, the need to retain and attract high-quality personnel, the importance of maintaining and enhancing the brand and reputation, and the need to address historical workplace culture and forward-leaning approach challenges.\n",
            "\n",
            "In comparison, the risk factors discussed in the Uber 10-K for prior years include the potential for Drivers to be classified as employees, workers, or quasi-employees instead of independent contractors, the competitive nature of the mobility, delivery, and logistics industries, the potential for operating expenses to increase significantly, the need to attract and maintain a critical mass of Drivers, consumers, merchants, Shippers, and Carriers, the need to retain and attract high-quality personnel, the importance of maintaining and enhancing the brand and reputation, and the need to address historical workplace culture and forward-leaning approach challenges.\n",
            "\n",
            "The risk factors discussed in the Uber 10-K for 2022\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nIn the Uber 10-K for 2022, the risk factors discussed include the potential for Drivers to be classified as employees, workers, or quasi-employees instead of independent contractors, the competitive nature of the mobility, delivery, and logistics industries, the potential for operating expenses to increase significantly, the need to attract and maintain a critical mass of Drivers, consumers, merchants, Shippers, and Carriers, the need to retain and attract high-quality personnel, the importance of maintaining and enhancing the brand and reputation, and the need to address historical workplace culture and forward-leaning approach challenges.\\n\\nIn comparison, the risk factors discussed in the Uber 10-K for prior years include the potential for Drivers to be classified as employees, workers, or quasi-employees instead of independent contractors, the competitive nature of the mobility, delivery, and logistics industries, the potential for operating expenses to increase significantly, the need to attract and maintain a critical mass of Drivers, consumers, merchants, Shippers, and Carriers, the need to retain and attract high-quality personnel, the importance of maintaining and enhancing the brand and reputation, and the need to address historical workplace culture and forward-leaning approach challenges.\\n\\nThe risk factors discussed in the Uber 10-K for 2022'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_query_str = \"Compare/contrast the risk factors described in the Uber 10-K across years. Give answer in bullet points.\"\n",
        "agent_chain.run(input=cross_query_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "xaBE8G_PmPok",
        "outputId": "47a3a370-022d-41a1-d5c4-32c1d631388d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: What were some of the legal proceedings against Uber in 2022?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Vector Index 2022\n",
            "Action Input: \"legal proceedings\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "Yes, legal proceedings are mentioned in the context information. The context information mentions that Uber is involved in legal proceedings, litigation, claims, and government investigations in the ordinary course of business, as well as class action lawsuits alleging that Uber entities conspired to injure certain participants in the taxi, hire-car, and limousine industries. The context information also mentions that Uber is subject to claims related to the classification of Drivers and the compliance of its business with applicable law, and that Uber is obligated to develop and maintain proper and effective internal controls over financial reporting.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent: \n",
            "Yes, legal proceedings are mentioned in the context information. The context information mentions that Uber is involved in legal proceedings, litigation, claims, and government investigations in the ordinary course of business, as well as class action lawsuits alleging that Uber entities conspired to injure certain participants in the taxi, hire-car, and limousine industries. The context information also mentions that Uber is subject to claims related to the classification of Drivers and the compliance of its business with applicable law, and that Uber is obligated to develop and maintain proper and effective internal controls over financial reporting.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-164462fae99c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'User: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Agent: {response}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    text_input = input(\"User: \")\n",
        "    response = agent_chain.run(input=text_input)\n",
        "    print(f\"Agent: {response}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('llm')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "4fc23e76f3ab0d08f73c715ca7eda992f68b82130559290d613113849e6bb006"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
